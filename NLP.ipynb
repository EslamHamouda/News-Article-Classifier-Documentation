{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d2b49b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "from tkinter import filedialog\n",
    "import pandas as pd\n",
    "\n",
    "class NewsClassifier:\n",
    "    def __init__(self):\n",
    "        self.classifier = None\n",
    "        self.vectorizer = None\n",
    "        \n",
    "    def preprocess(self, text):\n",
    "        # Remove punctuation\n",
    "        text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "        \n",
    "        # Tokenize the text\n",
    "        tokens = nltk.word_tokenize(text.lower())\n",
    "        \n",
    "        # Remove stop words and stem the words\n",
    "        stemmer = PorterStemmer()\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        stemmed_tokens = [stemmer.stem(token) for token in tokens if token not in stop_words]\n",
    "        \n",
    "        # Return the preprocessed text as a space-separated string\n",
    "        return ' '.join(stemmed_tokens)\n",
    "    \n",
    "    def train_model(self, X, y):\n",
    "        # Vectorize the input text data\n",
    "        vectorizer = CountVectorizer()\n",
    "        X = vectorizer.fit_transform(X)\n",
    "        \n",
    "        # Split the data into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Train a Naive Bayes classifier\n",
    "        classifier = MultinomialNB()\n",
    "        classifier.fit(X_train, y_train)\n",
    "        \n",
    "        self.classifier = classifier\n",
    "        self.vectorizer = vectorizer\n",
    "        \n",
    "        # Evaluate the model\n",
    "        self.evaluate_model(X_test, y_test)\n",
    "    \n",
    "    def evaluate_model(self, X_test, y_test):\n",
    "        # Predict the labels for the test dataset\n",
    "        y_pred = self.classifier.predict(X_test)\n",
    "        \n",
    "        # Calculate evaluation metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        recall = recall_score(y_test, y_pred, average='weighted')\n",
    "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "        messagebox.showinfo(\"Model Evaluation\", f\"Accuracy: {accuracy}\\nPrecision: {precision}\\nRecall: {recall}\\nF1-score: {f1}\")\n",
    "    \n",
    "    def predict_category(self, text):\n",
    "        preprocessed_text = self.preprocess(text)\n",
    "        text_vector = self.vectorizer.transform([preprocessed_text])\n",
    "        predicted_category = self.classifier.predict(text_vector)[0]\n",
    "        messagebox.showinfo(\"Category Prediction\", f\"The predicted category is: {predicted_category}\")\n",
    "\n",
    "    def browse_file(self):\n",
    "        file_path = filedialog.askopenfilename(filetypes=((\"CSV files\", \"*.csv\"), (\"All files\", \"*.*\")))\n",
    "        if file_path:\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "                category_column = 'Category'\n",
    "                text_column = 'Text'\n",
    "                categories = df[category_column].values\n",
    "                texts = df[text_column].values\n",
    "\n",
    "                X = [self.preprocess(text) for text in texts]\n",
    "                y = categories\n",
    "\n",
    "                self.train_model(X, y)\n",
    "            except Exception as e:\n",
    "                messagebox.showerror(\"Error\", str(e))\n",
    "    \n",
    "    def classify_text(self):\n",
    "        text = text_entry.get(\"1.0\", tk.END).strip()\n",
    "        if text:\n",
    "            self.predict_category(text)\n",
    "\n",
    "# Create an instance of the NewsClassifier class\n",
    "news_classifier = NewsClassifier()\n",
    "\n",
    "# Create the main GUI window\n",
    "window = tk.Tk()\n",
    "window.title(\"News Article Classifier\")\n",
    "\n",
    "# Create a label for the text entry\n",
    "text_label = tk.Label(window, text=\"Enter news article:\")\n",
    "text_label.pack()\n",
    "\n",
    "# Create a text entry field\n",
    "text_entry = tk.Text(window, height=10, width=50)\n",
    "text_entry.pack()\n",
    "\n",
    "# Create a button to classify the text\n",
    "classify_button = tk.Button(window, text=\"Classify\", command=news_classifier.classify_text)\n",
    "classify_button.pack()\n",
    "\n",
    "# Create a button to browse and load a CSV file\n",
    "browse_button = tk.Button(window, text=\"Browse\", command=news_classifier.browse_file)\n",
    "browse_button.pack()\n",
    "\n",
    "# Run the main GUI loop\n",
    "window.mainloop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d438e95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
